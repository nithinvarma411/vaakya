<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vaakya - Voice Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
        }
        .controls {
            text-align: center;
            margin: 20px 0;
        }
        button {
            background-color: #4CAF50;
            color: white;
            padding: 12px 24px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            margin: 0 10px;
        }
        button:hover {
            background-color: #45a049;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #stopBtn {
            background-color: #f44336;
        }
        #stopBtn:hover {
            background-color: #da190b;
        }
        .status {
            text-align: center;
            margin: 20px 0;
            font-weight: bold;
        }
        #transcription {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            min-height: 100px;
            margin-top: 20px;
        }
        .recording {
            color: #f44336;
            animation: pulse 1.5s infinite;
        }
        .listening {
            color: #2196F3;
            animation: pulse 1s infinite;
        }
        .wake-word-detected {
            color: #FF9800;
            animation: pulse 0.5s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        .wake-word-info {
            text-align: center;
            margin: 10px 0;
            font-style: italic;
            color: #666;
        }
        .sound-indicator {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background-color: #4CAF50;
            display: inline-block;
            margin-left: 10px;
            animation: soundPulse 1s infinite;
        }
        @keyframes soundPulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.2); }
            100% { transform: scale(1); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Vaakya Voice Assistant</h1>
        <p style="text-align: center;">Say "Hey Vaakya" to start recording automatically</p>
        
        <div class="wake-word-info">
            <span id="wakeWordStatus">Listening for wake word...</span>
            <span id="soundIndicator" class="sound-indicator" style="display: none;"></span>
        </div>
        
        <div class="controls">
            <button id="startBtn">Start Recording</button>
            <button id="stopBtn" disabled>Stop Recording</button>
        </div>
        
        <div class="status" id="status">Ready - Say "Hey Vaakya"</div>
        
        <div id="transcription">
            <h3>Transcription:</h3>
            <p id="transcriptText">Your transcription will appear here...</p>
        </div>
    </div>

    <audio id="wakeSound" preload="auto">
        <source src="data:audio/wav;base64,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ÊûÅÂú∞" type="audio/wav">
    </audio>
    <audio id="startSound" preload="auto">
        <source src="data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2/LDciUFLIHO8tiJNwgZaLvt559NEAxQp+PwtmMcBjiR1/LMeSwFJHfH79WQQAoUXrTp66hVFApGn+DxvGkeBzOH0/LMeSwFJHfH79WQQAoUXrTp66hVFApGn+DxvGkeBzOH0/LMeSwFJHfH79WQQAoUXrTp66hVFApGn+DxvGkeBzOH0/LMeSwFJHfH79WQQAoUXrTp66hVFApGn+DxvGkeBzOH0/LMeSwFJHfH79WQQAoUXrTp66hÊûÅÂú∞" type="audio/wav">
    </audio>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let silenceTimer = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let scriptProcessor = null;
        let silenceStartTime = null;
        let recordingStream = null;
        let vadInitialized = false;
        const SILENCE_THRESHOLD = 15; // Increased threshold for better detection
        const SILENCE_DURATION = 1500; // 1.5 seconds of silence
        const MIN_RECORDING_DURATION = 500; // Minimum recording time before allowing stop
        let recordingStartTime = null;

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusEl = document.getElementById('status');
        const transcriptText = document.getElementById('transcriptText');

        async function startRecording() {
            try {
                console.log('startRecording called');
                recordingStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                // Initialize audio context for VAD
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(recordingStream);
                scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);

                analyser.smoothingTimeConstant = 0.8;
                analyser.fftSize = 1024;

                microphone.connect(analyser);
                analyser.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);

                scriptProcessor.onaudioprocess = function() {
                    try {
                        const array = new Uint8Array(analyser.frequencyBinCount);
                        analyser.getByteFrequencyData(array);
                        let values = 0;

                        // Calculate RMS (Root Mean Square) for better voice detection
                        for (let i = 0; i < array.length; i++) {
                            values += array[i] * array[i];
                        }

                        const average = Math.sqrt(values / array.length);

                        if (average > SILENCE_THRESHOLD) {
                            // Voice detected
                            if (!isRecording) {
                                console.log('Voice detected, starting recording');
                                startMediaRecorder();
                            }
                            // Reset silence timer
                            if (silenceTimer) {
                                clearTimeout(silenceTimer);
                                silenceTimer = null;
                            }
                            silenceStartTime = null;
                        } else {
                            // Silence detected
                            if (isRecording && !silenceStartTime) {
                                // Only start silence timer if we've been recording for minimum duration
                                if (recordingStartTime && (Date.now() - recordingStartTime) > MIN_RECORDING_DURATION) {
                                    silenceStartTime = Date.now();
                                    silenceTimer = setTimeout(() => {
                                        console.log('Silence timeout reached, stopping recording');
                                        stopRecording();
                                    }, SILENCE_DURATION);
                                }
                            }
                        }
                    } catch (error) {
                        console.error('Error in VAD processing:', error);
                    }
                };

                isRecording = false; // Will be set to true when voice is detected
                startBtn.disabled = true;
                stopBtn.disabled = false;
                statusEl.textContent = 'Listening for voice...';
                statusEl.className = 'listening';
                transcriptText.textContent = 'Waiting for speech...';

            } catch (error) {
                console.error('Error accessing microphone:', error);
                statusEl.textContent = 'Error: Could not access microphone';
                statusEl.className = '';
            }
        }

        function startMediaRecorder() {
            mediaRecorder = new MediaRecorder(recordingStream);
            audioChunks = [];

            mediaRecorder.ondataavailable = event => {
                console.log('ondataavailable event fired');
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = async () => {
                console.log('mediaRecorder stopped');
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                await sendAudioForTranscription(audioBlob);
                // Don't stop the stream here as VAD is still running
            };

            mediaRecorder.start();
            console.log('mediaRecorder started');
            isRecording = true;
            statusEl.textContent = 'Recording... Speak now';
            statusEl.className = 'recording';
            transcriptText.textContent = 'Listening...';
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                console.log('stopRecording called');
                mediaRecorder.stop();
                isRecording = false;
                startBtn.disabled = false;
                stopBtn.disabled = true;
                statusEl.textContent = 'Processing audio...';
                statusEl.className = '';

                // Clean up VAD resources
                if (scriptProcessor) {
                    scriptProcessor.disconnect();
                    scriptProcessor = null;
                }
                if (analyser) {
                    analyser.disconnect();
                    analyser = null;
                }
                if (microphone) {
                    microphone.disconnect();
                    microphone = null;
                }
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                if (recordingStream) {
                    recordingStream.getTracks().forEach(track => track.stop());
                    recordingStream = null;
                }

                // Clear any pending silence timer
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
                silenceStartTime = null;
            }
        }

        async function sendAudioForTranscription(audioBlob) {
            try {
                console.log('sendAudioForTranscription called');
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.wav');
                
                const response = await fetch('http://localhost:8000/transcribe', {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    const data = await response.json();
                    console.log('Transcription received:', data.transcription);
                    transcriptText.textContent = data.transcription || "Transcription completed but no text returned";
                    statusEl.textContent = 'Transcription complete!';
                } else {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Transcription failed');
                }
            } catch (error) {
                console.error('Transcription error:', error);
                transcriptText.textContent = `Error: ${error.message}`;
                statusEl.textContent = 'Transcription failed';
            } finally {
                // Restart wake word detection after transcription completes
                setTimeout(() => {
                    startWakeWordDetection();
                    wakeWordStatus.textContent = 'Listening for wake word...';
                    wakeWordStatus.className = 'listening';
                }, 1000);
            }
        }

        let recognition = null;
        let isListeningForWakeWord = false;
        const wakeWordStatus = document.getElementById('wakeWordStatus');
        const soundIndicator = document.getElementById('soundIndicator');
        const wakeSound = document.getElementById('wakeSound');
        const startSound = document.getElementById('startSound');

        function initWakeWordDetection() {
            if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';

                recognition.onresult = function(event) {
                    let transcript = '';
                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        if (event.results[i].isFinal) {
                            transcript += event.results[i][0].transcript.toLowerCase();
                        }
                    }
                    
                    if (transcript.includes('hey vaakya') || transcript.includes('hey vakaya')) {
                        wakeWordDetected();
                    }
                    
                
                    if (transcript.trim().length > 0) {
                        soundIndicator.style.display = 'inline-block';
                    } else {
                        soundIndicator.style.display = 'none';
                    }
                };

                recognition.onerror = function(event) {
                    console.error('Speech recognition error:', event.error);
                    if (event.error === 'no-speech') {
                        soundIndicator.style.display = 'none';
                    }
                };

                recognition.onend = function() {
                    if (isListeningForWakeWord) {
                        setTimeout(() => {
                            try {
                                recognition.start();
                            } catch (e) {
                                console.error('Failed to restart recognition:', e);
                            }
                        }, 100);
                    }
                };

                startWakeWordDetection();
            } else {
                wakeWordStatus.textContent = 'Speech recognition not supported in this browser';
                console.warn('Speech recognition API not available');
            }
        }

        function startWakeWordDetection() {
            if (recognition) {
                try {
                    recognition.start();
                    isListeningForWakeWord = true;
                    wakeWordStatus.textContent = 'Listening for wake word...';
                    wakeWordStatus.className = 'listening';
                } catch (e) {
                    console.error('Failed to start speech recognition:', e);
                }
            }
        }

        function stopWakeWordDetection() {
            if (recognition) {
                try {
                    recognition.stop();
                    isListeningForWakeWord = false;
                    wakeWordStatus.textContent = 'Wake word detection stopped';
                    wakeWordStatus.className = '';
                } catch (e) {
                    console.error('Failed to stop speech recognition:', e);
                }
            }
        }

        function wakeWordDetected() {
            wakeSound.currentTime = 0;
            wakeSound.play().catch(e => console.log('Audio play failed:', e));
            
            wakeWordStatus.textContent = 'Wake word detected!';
            wakeWordStatus.className = 'wake-word-detected';
            
            // Stop wake word detection before starting recording
            stopWakeWordDetection();
            
            // Trigger the same functionality as clicking the start recording button
            startBtn.click();
        }



        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);

        window.addEventListener('load', function() {
            initWakeWordDetection();
        });
    </script>
</body>
</html>
